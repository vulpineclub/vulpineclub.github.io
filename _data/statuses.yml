- date: 2019-06-04 11:55:00 -0400
  severity: performance
  status: resolved
  summary: |
      High CPU Steal% is leading to performance issues.

      13:40: Scaled sidekiqs from 2 to 1 to reduce CPU pressure on web/streaming

      13:45: Linode tkt 12012372 open

      15:40: We've been moved to another host (live migration!!) and everything should be better.

- date: 2019-01-15 21:40:00 -0500
  severity: upgrade
  summary: upgrade to prod-20190115-01

- date: 2019-01-06 09:35:00 -0800
  severity: outage
  status: resolved
  summary: |
      during work to improve system reliability and monitoring, everything was broken for a short period of time.

      09:35: web services (API, streaming) offline

      10:00: web services back online, background processing (Sidekiq) still offline

      10:45: background processing back online, handling backlog

      11:00: everything back to real time!

- date: 2018-12-30 10:30:00 -0800
  severity: upgrade
  status: resolved
  summary: deploying prod-20181229-01.  this was about a ~10 minute outage for the reboot.

- date: 2018-12-24 19:05:00 -0500
  severity: outage
  status: resolved
  summary: |
      19:05: deployed prod-20181224-01. this broke docker and/or the kernel again. sigh. reboot is complete as of 19:20.

      19:25: ugh, tried something to fix the previous problem, f'd the entire stack again.  rebooting.

      19:45: okay i think everything is okay for now... had to fix up a couple loose ends, but we're... up!  ish!  kinda!!

      still dunno what's going on :( ... i have upgraded to a very latest kernel, tho, let's see if this fixes something.

- date: 2018-12-12 22:50:00 -0500
  severity: outage
  summary: |
      22:50: deployed prod-20181212-01, which has a possible fix for bridge.joinmastodon.org not working w/ vulpine.club

      23:05: that thing docker was doing last month is happening again, o no.  system is back up and working good, will investigate further at some later time :)

- date: 2018-12-10 23:15:00 -0500
  severity: outage
  status: resolved
  summary: |
      disk filled up, oops

      23:22: I think the site is broken but I'm in bed so I'm gonna just kinda hope it auto-corrects for a few minutes

      23:28: disk is full, hang loose

      23:35: okay, cleaned up some ballast, now gonna expand the diskkkkk

      23:38: booting........

      23:41: things are starting up.  pre-emptively fixing elasticsearch :)

      23:50: everything's cool

- date: 2018-12-02 18:00:00 -0500
  severity: brief
  summary: |
      restarted nginx to re-enable its cache and move some storage around

      i believe that mastodon web fe is not handling backend file changes very well; i'll get 404s and the like trying to load packs that were valid when i last did a shift-reload, but aren't valid now

      one of the things that i did alongside the cloudfront migration was turn off nginx's cache, because it was pointless.  however, an important part of it is that it will maintain missing files for awhile

      so i've turned it back on... let's see how this goes

- date: 2018-12-02 16:20:00 -0500
  severity: upgrade
  summary: deployed prod-20181202-01

- date: 2018-12-01 16:35:00 -0500
  severity: upgrade
  summary: deployed prod-20181201-01

- date: 2018-11-30 22:05:00 -0500
  severity: upgrade
  summary: actually deployed prod-20181130-01 again... forgot that i still had automated builds turned on, whoooops

- date: 2018-11-30 21:35:00 -0500
  severity: upgrade
  summary: deployed prod-20181130-01

- date: 2018-11-26 17:30:00 -0500
  severity: upgrade
  summary: deployed prod-20181126-01

- date: 2018-11-26 14:15:00 -0500
  severity: outage
  status: resolved
  summary: |
      14:15: taking the website down for a few minutes to fix docker, i hope

      14:35: looking like i may have nuked the bad network config, rebooting to make sure

      14:45: nginx didn't want to come back up cuz of a misconfiguration (??!) but that is fixed and the site appears to be working.

      i believe this was a success! will see later on when i do an upgrade :)

- date: 2018-11-15 19:15:00 -0500
  severity: outage
  status: resolved
  summary: |
      19:15: docker blew up on me again, working on it...

      19:30: looks like i ended up with a whole bunch of `Nov 16 00:24:18 smithwicks kernel: [69141.318334] unregister_netdevice: waiting for veth61859a0 to become free. Usage count = 9`

      19:40: idk why docker is mad

- date: 2018-11-15 00:05:01 -0500
  severity: outage
  status: resolved
  summary: system crash during upgrade, fixing...

            - yeah, no idea what the f happened, but rebooting it brought everything back up.  jfc, second time i've had to hard-reboot a machine today.  the first time was because telegram was jammed up on my laptop.  _telegram!_

- date: 2018-11-15 00:05:00 -0500
  severity: upgrade
  summary: upgrade to prod-20181114-01

            - Fix loading indicator inconsistency (#9252)

            - Local-only statuses excluded from atom feeds, unauthenticated streams

- date: 2018-11-13 23:30:00 -0500
  severity: maintenance
  summary: restarted the postgresql server to increase max_connections from 100 to 150

- date: 2018-11-11 17:20:00 -0500
  severity: maintenance
  status: resolved
  summary: rebooting the server, as it has been nearly 3 months.  also doing some adjustments to docker-compose networks, so now's a good time to take everything down for a sec... (and we're back up after about 10 minutes)

- date: 2018-11-09 21:20:00 -0500
  severity: upgrade
  summary: upgrade to prod-20181109-01

            - Implement adding a user to a list from their profile (#9062)

            - Allow joining several hashtags in a single column (#8904)

            - Temporarily hold timeline if mouse moved recently (fixes 8630) (#9200)

            - Increase default column width from 330px to 350px (#9227)

            - Add "Show thread" link to self-replies (#9228)

- date: 2018-11-08 19:30:00 -0500
  severity: outage
  status: resolved
  summary: web UI was broken, degraded, or totally fine for various people, due to an incorrect configuration of the CloudFront caching behavior. this was declared resolved at 21:45 -0500.
  incident: 2018-11-08-01

- date: 2018-11-08 19:15:00 -0500
  severity: upgrade
  summary: upgrade to prod-20181108-02 (cc7ee2dd5a3e) (minor graphics updates)

- date: 2018-11-08 16:55:00 -0500
  severity: upgrade
  incident: 2018-11-08-01
  summary: upgrade to prod-20181108-01 (a247d59d6d7d)

            - only change since prod-20181105-01 was serving local assets (/packs, /emoji, /sounds) via CloudFront, for ✨performance✨

            - this experiment began a multi-hours degraded performance situation; see the attached incident for details.

- date: 2018-11-06 00:30:00 -0500
  severity: degraded performance
  status: resolved
  summary: queue backlog because @rey got bored and retried the entire dead queue again, sorry

            - resolved at 2018-11-06 00:50:00 -0500

- date: 2018-11-06 00:00:00 -0500
  severity: upgrade
  summary: upgrade to prod-20181105-01

- date: 2018-10-31 00:50:00 -0400
  severity: upgrade
  summary: upgrade to prod-20181030-02 (regression)

- date: 2018-10-30 19:45:00 -0400
  severity: upgrade
  summary: upgrade to prod-20181030-01

- date: 2018-10-28 20:45:00 -0400
  severity: upgrade
  summary: upgrade to prod-20181028-01, system updates

- date: 2018-10-27 23:45:00 -0400
  severity: upgrade
  summary: upgrade to prod-20181027-01

- date: 2018-10-23 19:20:00 -0400
  severity: upgrade
  summary: upgrade to prod-20181023-01.  commits pulled from glitch-soc include

            - Put a video camera emoji or a picture frame emoji instead of “.”

            - Do not move CWs to toot body when toot body is empty, Fixes \#395

            - Attempt at fixing inline video player

            - Update mediaGallery component's width when opening CWs

            - Force sensitive content flag when posting a toot with a CW

            - Focus the UI when pressing Escape in the CW field

            - Fix fav/boosts hotkeys not working on detailed statuses

            - Fix deleting individual notifications from glitch-soc's web interface

- date: 2018-10-18 11:45:00 -0400
  severity: brief outage
  summary: restarted the web workers to increase character limit from 666 to 667.  [justification](https://vulpine.club/@rey/100917382859684450)

- date: 2018-10-15 21:52:00 -0400
  severity: brief outage
  summary: the last outage didn't take, so poking it again

- date: 2018-10-15 21:35:00 -0400
  severity: brief outage
  summary: changed S3_ALIAS_HOST from d2pc52zrmidoft.cloudfront.net to cdn-assets.vulpine.owogroupllc.com ... same thing, different name

- date: 2018-10-14 23:35:00 -0400
  severity: upgrade
  summary: upgrade to prod-20181014-02; iterate glitchfox

- date: 2018-10-14 22:00:00 -0400
  severity: upgrade
  summary: upgrade to prod-20181014-01; merge from glitchsoc, add cdn-assets.vulpine.owogroupllc.com to CSP

- date: 2018-10-14 21:00:00 -0400
  severity: degraded availability
  summary: restarted vulpine.club twice in rapid succession, in an attempt to switch to a new hostname
           for media assets.  Turns out that this requires a bit more preparation work, which will be
           done during an upcoming upgrade.

- date: 2018-10-14 02:15:00 +0000
  severity: brief outage
  summary: restarted vulpine.club web frontends to increase the character limit from 500 to 666.  h/t @kellerfuchs

- date: 2018-10-11 21:45:00 -0400
  severity: upgrade
  summary: upgrade from [prod-20181009-01 to prod-20181011-01](https://github.com/vulpineclub/mastodon/compare/prod-20181009-01...prod-20181011-01)

           - Cherry-pick "Improve signature verification safeguards (#8959)" for security

- date: 2018-10-09 18:24:00 -0400
  severity: upgrade
  summary: upgrade from [prod-20181007-02 to prod-20181009-01](https://github.com/vulpineclub/mastodon/compare/prod-20181007-02...prod-20181009-01)

           - Add conversations API (#8832)

           - Fixed error occurrence when pinning the DM column. (#8922)

- date: 2018-10-07 21:10:00 -0400
  severity: upgrade
  summary: upgrade from [prod-20181007-01 to prod-20181007-02](https://github.com/vulpineclub/mastodon/compare/prod-20181007-01...prod-20181007-02)

           - a couple quick minor tweaks from glitch-soc

- date: 2018-10-07 20:15:00 -0400
  severity: upgrade
  summary: upgrade from [prod-20180928-01 to prod-20181007-01](https://github.com/vulpineclub/mastodon/compare/prod-20180928-01...prod-20181007-01)

           - actually a whole bunch of stuff changed, not gonna be able to document it all lolz

- date: 2018-09-28 11:45:00 -0400
  severity: upgrade
  summary: upgrade from [prod-20180923-02 to prod-20180928-01](https://github.com/vulpineclub/mastodon/compare/prod-20180923-02...prod-20180928-01)

           - new version number string, 40 MB limit on audio uploads (same as video), 12 MB limit on images (was 8 MB)

- date: 2018-09-24 19:25:00 -0400
  severity: degraded performance
  summary: Rey pushed the wrong buttons and now has no idea which of the "production" images has the fix for the
           previous problem, cuz the tags got all f'd up. So we may or may not have the previous problem for the
           next couple whiles. Whoops.
           
           - 19:30 - waiting for a Docker Hub build... [build details](https://hub.docker.com/r/vulpineclub/mastodon/builds/bv2zaw3q9yywle3jwif7bxv/)

           - 19:45 - queues seem pretty okay rn? the original thing that f'd it up was decreasing the sidekiq scale
             factor from 4 to 3. however, i bumped it back up to 4 and we're good. maybe it just needs to be 4.
             still gonna wait for the rebuild tho; dirty builds sketch me out.

           - 23:15 - oh! hi! okay so it finished the build and i deployed it and i think things are gonna be fine. honestly they were probably
             fine all along, i was just being impatient.  i'm gonna go ahead and -- _bing!_ -- turn off the seatbelt sign and

- date: 2018-09-23 02:20:00 +0000
  severity: degraded performance
  summary: Rey worked a queue backlog and resource exhaustion issue caused by an edge case in the processing of
           certain media attachments. This problem was unique to vulpine.club.
  incident: 2018-09-23-01

- date: 2018-09-23 02:35:00 -0400
  severity: upgrade
  summary: upgrade from [prod-20180923-01 to prod-20180923-02](https://github.com/vulpineclub/mastodon/compare/prod-20180923-01...prod-20180923-02)

- date: 2018-09-23 00:00:00 -0400
  severity: upgrade
  summary: upgrade from [prod-20180918-01 to prod-20180923-01](https://github.com/vulpineclub/mastodon/compare/prod-20180918-01...prod-20180923-01)

- date: 2018-09-18 23:30:00 +0000
  severity: upgrade
  summary: upgrade from [prod-20180912-01 to prod-20180918-01](https://github.com/vulpineclub/mastodon/compare/prod-20180912-01...prod-20180918-01)

- date: 2018-09-18 20:30:00 +0000
  severity: informational
  summary: created this page
